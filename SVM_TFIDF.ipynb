{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27870e93-ac13-49f0-9e9d-b14383e03e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import dump\n",
    "import pickle\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ad977c-256c-422d-bb90-c0526b1d693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    κ-  theta\\  non-stellar  'heavy  regge  unitary  extension  ferromagnetic  \\\n",
      "0  0.0     0.0          0.0     0.0    0.0      0.0        0.0            0.0   \n",
      "1  0.0     0.0          0.0     0.0    0.0      0.0        0.0            0.0   \n",
      "2  0.0     0.0          0.0     0.0    0.0      0.0        0.0            0.0   \n",
      "3  0.0     0.0          0.0     0.0    0.0      0.0        0.0            0.0   \n",
      "4  0.0     0.0          0.0     0.0    0.0      0.0        0.0            0.0   \n",
      "\n",
      "   laenen   xp  ...  wavenumber  'every  calorimetry   z4  negligible  \\\n",
      "0     0.0  0.0  ...         0.0     0.0          0.0  0.0         0.0   \n",
      "1     0.0  0.0  ...         0.0     0.0          0.0  0.0         0.0   \n",
      "2     0.0  0.0  ...         0.0     0.0          0.0  0.0         0.0   \n",
      "3     0.0  0.0  ...         0.0     0.0          0.0  0.0         0.0   \n",
      "4     0.0  0.0  ...         0.0     0.0          0.0  0.0         0.0   \n",
      "\n",
      "   antiferromagnetically  const  l+\\frac  witten      cat_one_hot  \n",
      "0                    0.0    0.0      0.0     0.0  [1, 0, 0, 0, 0]  \n",
      "1                    0.0    0.0      0.0     0.0  [1, 0, 0, 0, 0]  \n",
      "2                    0.0    0.0      0.0     0.0  [1, 0, 0, 0, 0]  \n",
      "3                    0.0    0.0      0.0     0.0  [1, 0, 0, 0, 0]  \n",
      "4                    0.0    0.0      0.0     0.0  [1, 0, 0, 0, 0]  \n",
      "\n",
      "[5 rows x 19028 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "datos = pd.read_csv('tfidf_matrix.csv')\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame para verificar que se haya cargado correctamente\n",
    "print(datos.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e4a1d7-a0d4-46a7-8390-972cfa39ef97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import dump\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from joblib import dump\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "import os\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "def crear_directorio(nombre_carpeta):\n",
    "    directorio_actual = os.getcwd()\n",
    "    print(\"El directorio actual es:\", directorio_actual)\n",
    "    ruta_nueva_carpeta = os.path.join(directorio_actual, nombre_carpeta)\n",
    "    # Verificar si la carpeta ya existe\n",
    "    if not os.path.exists(ruta_nueva_carpeta):\n",
    "        # Crear la carpeta si no existe\n",
    "        os.mkdir(ruta_nueva_carpeta)\n",
    "        print(\"Se creó la carpeta\", nombre_carpeta, \"en\", directorio_actual)\n",
    "    else:\n",
    "        print(\"La carpeta\", nombre_carpeta, \"ya existe en\", directorio_actual)\n",
    "\n",
    "    ruta_modificada = ruta_nueva_carpeta.replace(\"\\\\\",\"/\")\n",
    "    return ruta_modificada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd2f66e-a6e4-4b35-95e7-44dfc7de79d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_method(dataset,max_iter_1,test_size_1=None, cv=None):\n",
    "    # Separar las características (X) de las etiquetas (y)\n",
    "    validacion = \"\"\n",
    "    X = dataset.drop('cat_one_hot', axis=1)  # Eliminar la columna 'cat_one_hot' para obtener las características\n",
    "    y = dataset['cat_one_hot']  # Obtener solo la columna 'cat_one_hot' para obtener las etiquetas\n",
    "\n",
    "    if test_size_1:\n",
    "        # Dividir el conjunto de datos en conjunto de entrenamiento y conjunto de prueba\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size_1, random_state=42)\n",
    "        \n",
    "        # Inicializar el modelo de regresión logística para clasificación multiclase\n",
    "        svm_classifier = SVC(kernel='linear')\n",
    "        \n",
    "        # Entrenar el modelo de regresión logística\n",
    "        svm_classifier.fit(X_train, y_train)\n",
    "        \n",
    "        # Hacer predicciones con el modelo entrenado\n",
    "        predicciones = svm_classifier.predict(X_test)\n",
    "        \n",
    "        # Evaluar el rendimiento del modelo\n",
    "        exactitud = accuracy_score(y_test, predicciones)\n",
    "        precision = precision_score(y_test, predicciones, average='weighted')\n",
    "        recall = recall_score(y_test, predicciones, average='weighted')\n",
    "        f1 = f1_score(y_test, predicciones, average='weighted')\n",
    "        matriz_confusion = confusion_matrix(y_test, predicciones)\n",
    "        \n",
    "        # Crear un mapa de calor para la matriz de confusión\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title('Matriz de Confusión con test = ' + str(test_size_1))\n",
    "        plt.xlabel('Etiquetas Predichas')\n",
    "        plt.ylabel('Etiquetas Verdaderas')\n",
    "    \n",
    "        # Guardar la figura de la matriz de confusión\n",
    "        direccion_nueva_carpeta = \"SVM_val_sim_\"\n",
    "        ruta_figura_incom = crear_directorio(direccion_nueva_carpeta)\n",
    "        ruta_figura = ruta_figura_incom + \"/matriz_confusion_test_\" + str(test_size_1) +  \".png\"\n",
    "        plt.savefig(ruta_figura)\n",
    "        print(\"Matriz de confusión guardada en:\", ruta_figura)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Exactitud del modelo:\", exactitud)\n",
    "        print(\"Precisión del modelo:\", precision)\n",
    "        print(\"Recall del modelo:\", recall)\n",
    "        print(\"Puntuación F1 del modelo:\", f1)\n",
    "    \n",
    "        resultados = {}\n",
    "        resultados[\"exactitud\"] = exactitud\n",
    "        resultados[\"precision\"] = precision\n",
    "        resultados[\"recall\"] = recall\n",
    "        resultados[\"f1\"] = f1\n",
    "        #resultados[\"matriz_confusion\"] = matriz_confusion\n",
    "        validacion = \"simple\"\n",
    "        ruta_para_modelo = ruta_figura_incom + \"/SVM_val_test\" + str(test_size_1) + \".pkl\"\n",
    "        with open(ruta_para_modelo, 'wb') as archivo:\n",
    "            pickle.dump(svm_classifier, archivo)\n",
    "\n",
    "    elif cv:\n",
    "        # Inicializar el modelo de regresión logística para clasificación multiclase\n",
    "        svm_classifier = SVC(kernel='linear')\n",
    "        \n",
    "        # Realizar validación cruzada\n",
    "        predicciones = cross_val_predict(svm_classifier, X, y, cv=cv)\n",
    "        # Evaluar el rendimiento del modelo\n",
    "        exactitud = accuracy_score(y, predicciones)\n",
    "        precision = precision_score(y, predicciones, average='weighted')\n",
    "        recall = recall_score(y, predicciones, average='weighted')\n",
    "        f1 = f1_score(y, predicciones, average='weighted')\n",
    "        matriz_confusion = confusion_matrix(y, predicciones)\n",
    "         \n",
    "        # Crear un mapa de calor para la matriz de confusión\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(matriz_confusion, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "        plt.title('Matriz de Confusión con Validación Cruzada (cv = ' + str(cv) + ')')\n",
    "        plt.xlabel('Etiquetas Predichas')\n",
    "        plt.ylabel('Etiquetas Verdaderas')\n",
    "\n",
    "        # Guardar la figura de la matriz de confusión\n",
    "        direccion_nueva_carpeta = \"SVM_val_cruz\"\n",
    "        ruta_figura_incom = crear_directorio(direccion_nueva_carpeta)\n",
    "        ruta_figura = ruta_figura_incom + \"/matriz_confusion_cv_\" + str(cv) + \".png\"\n",
    "        plt.savefig(ruta_figura)\n",
    "        print(\"Matriz de confusión guardada en:\", ruta_figura)\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Exactitud media:\", exactitud)\n",
    "        print(\"Precisión media:\", precision)\n",
    "        print(\"Recall media:\", recall)\n",
    "        print(\"Puntuación F1 media:\", f1)\n",
    "\n",
    "        resultados = {}\n",
    "        resultados[\"exactitud_media\"] = exactitud\n",
    "        resultados[\"precision_media\"] = precision\n",
    "        resultados[\"recall_media\"] = recall\n",
    "        resultados[\"f1_media\"] = f1\n",
    "        validacion = \"cruz\"\n",
    "        ruta_para_modelo = ruta_figura_incom + \"/SVM_val_cruz\" + str(cv) + \".pkl\"\n",
    "        with open(ruta_para_modelo, 'wb') as archivo:\n",
    "            pickle.dump(svm_classifier, archivo)\n",
    "    else:\n",
    "        print(\"Por favor, proporciona el tamaño de prueba (test_size_1) o el número de pliegues de validación cruzada (cv).\")\n",
    "        resultados = None\n",
    "    \n",
    "    return resultados,validacion,ruta_figura_incom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81071125-1b5f-4761-b974-37ba9f8679b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "def almacenar_informacion(resultados_finales,validacion,ruta_figura_incom):\n",
    "    if validacion == \"simple\":\n",
    "        ruta_archivo = ruta_figura_incom + \"/SVM_val_simple.json\"\n",
    "        with open(ruta_archivo, \"w\") as archivo:\n",
    "            json.dump(resultados_finales, archivo)\n",
    "        \n",
    "        print(\"Diccionario guardado como archivo JSON en:\", ruta_archivo)\n",
    "    elif validacion == \"cruz\":\n",
    "        ruta_archivo =  ruta_figura_incom + \"/SVM_val_cruz.json\"\n",
    "        with open(ruta_archivo, \"w\") as archivo:\n",
    "            json.dump(resultados_finales, archivo)\n",
    "        \n",
    "        print(\"Diccionario guardado como archivo JSON en:\", ruta_archivo)\n",
    "\n",
    "# Inicializar una lista vacía para almacenar los valores\n",
    "lista_valores = []\n",
    "ruta_figura_incom = \"\"\n",
    "# Bucle for para generar los valores en incrementos de 0.10 hasta 0.9\n",
    "for i in range(1, 10):\n",
    "    valor = i / 10.0\n",
    "    lista_valores.append(valor)\n",
    "\n",
    "resultados_finales_val_simple = {}\n",
    "resultados_finales_val_cruz = {}\n",
    "\n",
    "experimento = 1\n",
    "test_size_1 = 0\n",
    "h = 1000\n",
    "for i in lista_valores:\n",
    "    resultados_finales_val_simple[\"Experimento_LR_\" + str(experimento) + \"_test_\" + str(i)],validacion,ruta_figura_incom = SVM_method(datos,h,test_size_1=i)\n",
    "    experimento = experimento + 1\n",
    "\n",
    "almacenar_informacion(resultados_finales_val_simple,validacion,ruta_figura_incom)\n",
    "\n",
    "lista = list(range(2, 11))\n",
    "for j in lista:\n",
    "    resultados_finales_val_cruz[\"Experimento_LR_\" + str(experimento) + \"_test_\" + str(j)],validacion,ruta_figura_incom = SVM_method(datos,h,cv=j)\n",
    "\n",
    "almacenar_informacion(resultados_finales_val_cruz,validacion,ruta_figura_incom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5138c3d5-f0ae-4a3e-8ca0-4795433407c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
